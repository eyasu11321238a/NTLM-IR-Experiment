{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e345b44",
   "metadata": {},
   "source": [
    "### <code>Dirichlet Model with Smoothing Parameter</code>\n",
    "\n",
    "#### **Smoothed Probability**\n",
    "\n",
    "The smoothed probability of a term $( w )$ given a document $( d )$ using Dirichlet smoothing is given by:\n",
    "\n",
    "$$p_{\\text{Dir}}(w|d) = \\frac{c(w, d) + \\mu \\cdot p(w|C)}{|d| + \\mu} \\text{........................Eq(1) }$$\n",
    "\n",
    "where:\n",
    "- $c(w, d)$  is the count of term $( w )$ in document $( d )$.\n",
    "- $|d|$  is the total number of terms in document $( d )$.\n",
    "- $\\mu$ is the Dirichlet smoothing parameter.\n",
    "- $p(w|C)$ is the probability of term $( w )$ in the entire collection $( C )$.\n",
    "\n",
    "\n",
    "#### **Collection Probability**\n",
    "\n",
    "The probability of term $( w )$ in the entire collection $( C )$ is:\n",
    "\n",
    "$$p(w|C) = \\frac{f(w, C)}{|C|}\\text{........................Eq(2) }$$\n",
    "\n",
    "where:\n",
    "- $f(w, C)$ is the count or frequency of term $( w )$ in the entire collection $( C )$.\n",
    "- $|C|$ is the total number of terms in the entire collection.\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e0c17a-fdc0-4efe-aa7b-f508fea422db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:33.436638Z",
     "start_time": "2024-06-10T09:33:33.431372Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4583629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:34.336654Z",
     "start_time": "2024-06-10T09:33:34.330001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME set to: C:\\Program Files\\Java\\jdk-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set JAVA_HOME environment variable\n",
    "java_home = r\"C:\\Program Files\\Java\\jdk-22\"   # adjust your java JDK folder \n",
    "os.environ[\"JAVA_HOME\"] = java_home\n",
    "\n",
    "# Verify that JAVA_HOME is set correctly\n",
    "print(\"JAVA_HOME set to:\", os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37967072-86dd-4463-b363-d4927841aa6f",
   "metadata": {},
   "source": [
    "### Loading the Topics & qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad82fa7-400c-4ee7-bc67-ea7338055854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:36.603910Z",
     "start_time": "2024-06-10T09:33:36.529773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the relative paths based on the notebook's location\n",
    "#topics_path = os.path.join(\"..\", \"Data\", \"AP_Doc\", \"ap\", \"topics\", \"all_topics_fixed.txt\")\n",
    "#qrels_path = os.path.join(\"..\", \"Data\", \"AP_Doc\", \"ap\", \"qrels\", \"AP_only.txt\")\n",
    "\n",
    "topics_path = os.path.join(\"..\", \"Data\", \"WSJ_Doc\", \"wsj\", \"topics\", \"all_topics_fixed.txt\")\n",
    "qrels_path = os.path.join(\"..\", \"Data\", \"WSJ_Doc\", \"wsj\", \"qrels\", \"WSJ_only.txt\")\n",
    "\n",
    "# Load topics and qrels from text files\n",
    "topics = pt.io.read_topics(topics_path)\n",
    "qrels = pt.io.read_qrels(qrels_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c158cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:37.429338Z",
     "start_time": "2024-06-10T09:33:37.407558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861203-0077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861204-0160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861204-0167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861209-0043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>WSJ861209-0128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104283</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920316-0108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104284</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920317-0087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104285</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920319-0108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104286</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920323-0193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104287</th>\n",
       "      <td>200</td>\n",
       "      <td>WSJ920324-0109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qid           docno  label\n",
       "0        51  WSJ861203-0077      0\n",
       "1        51  WSJ861204-0160      0\n",
       "2        51  WSJ861204-0167      0\n",
       "3        51  WSJ861209-0043      0\n",
       "4        51  WSJ861209-0128      0\n",
       "...     ...             ...    ...\n",
       "104283  200  WSJ920316-0108      0\n",
       "104284  200  WSJ920317-0087      0\n",
       "104285  200  WSJ920319-0108      0\n",
       "104286  200  WSJ920323-0193      0\n",
       "104287  200  WSJ920324-0109      0\n",
       "\n",
       "[104288 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa481a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>airbus subsidies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>south african sanctions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>leveraged buyouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>satellite launch contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>insider trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>196</td>\n",
       "      <td>school choice voucher system and its effects u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>197</td>\n",
       "      <td>reform of the jurisprudence system to stop jur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>198</td>\n",
       "      <td>gene therapy and its benefits to humankind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>199</td>\n",
       "      <td>legality of medically assisted suicides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>200</td>\n",
       "      <td>impact of foreign textile imports on u s texti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                              query\n",
       "0     51                                   airbus subsidies\n",
       "1     52                            south african sanctions\n",
       "2     53                                  leveraged buyouts\n",
       "3     54                         satellite launch contracts\n",
       "4     55                                    insider trading\n",
       "..   ...                                                ...\n",
       "145  196  school choice voucher system and its effects u...\n",
       "146  197  reform of the jurisprudence system to stop jur...\n",
       "147  198         gene therapy and its benefits to humankind\n",
       "148  199            legality of medically assisted suicides\n",
       "149  200  impact of foreign textile imports on u s texti...\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6741e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "506c9a35",
   "metadata": {},
   "source": [
    "#### AP TREC Files Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed9d4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T09:33:46.295242Z",
     "start_time": "2024-06-10T09:33:38.366637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to parse the TREC file\n",
    "def parse_trec_file(trec_file_path):\n",
    "    doc_texts = {}\n",
    "    current_doc_id = None\n",
    "    current_text = []\n",
    "    \n",
    "    encodings = ['utf-8', 'latin-1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(trec_file_path, 'r', encoding=encoding, errors='ignore') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('<DOCNO>'):\n",
    "                        current_doc_id = line.strip().replace('<DOCNO>', '').replace('</DOCNO>', '').strip()\n",
    "                    elif line.startswith('</TEXT>'):\n",
    "                        if current_doc_id:\n",
    "                            doc_texts[current_doc_id] = ' '.join(current_text)\n",
    "                            current_doc_id = None\n",
    "                            current_text = []\n",
    "                    elif current_doc_id:\n",
    "                        if not (line.startswith('<DOC>') or line.startswith('</DOC>') or line.startswith('<FILEID>') or\n",
    "                                line.startswith('<FIRST>') or line.startswith('<SECOND>') or line.startswith('<HEAD>') or\n",
    "                                line.startswith('<DATELINE>') or line.startswith('<TEXT>')):\n",
    "                            current_text.append(line.strip())\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue  \n",
    "\n",
    "    return doc_texts\n",
    "\n",
    "# Path to your concatenated TREC file\n",
    "#trec_file_path = os.path.join(\"..\", \"Data\", \"AP_Doc\", \"ap\", \"concatenated\", \"concatenated_documents.txt\")\n",
    "trec_file_path = os.path.join(\"..\", \"Data\", \"WSJ_DOC\", \"wsj\", \"concatenated_WSJ\", \"concatenated_WSJ.txt\")\n",
    "\n",
    "# Parse the document texts\n",
    "doc_texts = parse_trec_file(trec_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb45b1",
   "metadata": {},
   "source": [
    "#### WSJ TREC Files Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d660172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_trec_file(trec_file_path):\n",
    "    doc_texts = {}\n",
    "    current_doc_id = None\n",
    "    current_text = []\n",
    "    \n",
    "    encodings = ['utf-8', 'latin-1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(trec_file_path, 'r', encoding=encoding, errors='ignore') as file:\n",
    "                for line in file:\n",
    "                    if line.startswith('<DOCNO>'):\n",
    "                        current_doc_id = line.strip().replace('<DOCNO>', '').replace('</DOCNO>', '').strip()\n",
    "                    elif line.startswith('</TEXT>'):\n",
    "                        if current_doc_id:\n",
    "                            doc_texts[current_doc_id] = ' '.join(current_text)\n",
    "                            current_doc_id = None\n",
    "                            current_text = []\n",
    "                    elif current_doc_id:\n",
    "                        if not (line.startswith('<DOC>') or line.startswith('</DOC>') or line.startswith('<FILEID>') or\n",
    "                                line.startswith('<FIRST>') or line.startswith('<SECOND>') or line.startswith('<HEAD>') or\n",
    "                                line.startswith('<DATELINE>') or line.startswith('<TEXT>') or \n",
    "                                line.startswith('<HL>') or line.startswith('</HL>') or \n",
    "                                line.startswith('<DD>') or line.startswith('</DD>') or \n",
    "                                line.startswith('<SO>') or line.startswith('</SO>') or \n",
    "                                line.startswith('<IN>') or line.startswith('</IN>')):\n",
    "                            current_text.append(line.strip())\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue  \n",
    "\n",
    "    return doc_texts\n",
    "\n",
    "# Path to your concatenated TREC file\n",
    "# trec_file_path = os.path.join(\"..\", \"Data\", \"AP_Doc\", \"ap\", \"concatenated\", \"concatenated_documents.txt\")\n",
    "trec_file_path = os.path.join(\"..\", \"Data\", \"WSJ_DOC\", \"wsj\", \"concatenated_WSJ\", \"concatenated_WSJ.txt\")\n",
    "\n",
    "# Parse the document texts\n",
    "doc_texts = parse_trec_file(trec_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d850bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(list(doc_texts.items())[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f34e3",
   "metadata": {},
   "source": [
    "#### Dirichlet Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "281f65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "mu = 1500 \n",
    "\n",
    "# Preprocess documents\n",
    "doc_lengths = {}\n",
    "term_doc_freq = defaultdict(Counter)\n",
    "total_term_count = Counter()\n",
    "collection_length = 0\n",
    "\n",
    "# Tokenizing and gathering statistics\n",
    "for docno, text in doc_texts.items():\n",
    "    tokens = text.lower().split()\n",
    "    doc_length = len(tokens)\n",
    "    doc_lengths[docno] = doc_length\n",
    "    term_doc_freq[docno].update(tokens)\n",
    "    total_term_count.update(tokens)\n",
    "    collection_length += doc_length\n",
    "\n",
    "# Calculate P(w|C) for the collection\n",
    "P_w_C = {word: count / collection_length for word, count in total_term_count.items()} # ..... Eq(2)\n",
    "\n",
    "# Function to compute Dirichlet smoothed P(w|D)\n",
    "def dirichlet_smoothed_P_w_D(word, docno):\n",
    "    doc_length = doc_lengths[docno]\n",
    "    word_count_in_doc = term_doc_freq[docno][word]\n",
    "    P_w_C_word = P_w_C.get(word, 0)\n",
    "    return (word_count_in_doc + mu * P_w_C_word) / (doc_length + mu) # ..... Eq(1)\n",
    "\n",
    "# Scoring function\n",
    "def score_document(query, docno):\n",
    "    query_tokens = query.lower().split()\n",
    "    score = 0.0\n",
    "    for token in query_tokens:\n",
    "        P_w_D = dirichlet_smoothed_P_w_D(token, docno)\n",
    "        if P_w_D > 0:\n",
    "            score += np.log(P_w_D)\n",
    "    return score\n",
    "\n",
    "# Calculate scores for each query-document pair and rank them\n",
    "results = []\n",
    "\n",
    "for index, row in topics.iterrows():\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    scores = []\n",
    "    for docno in doc_texts.keys():\n",
    "        score = score_document(query, docno)\n",
    "        scores.append((docno, score))\n",
    "    \n",
    "    # Sort scores in descending order and assign ranks\n",
    "    ranked_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    for rank, (doc_id, score) in enumerate(ranked_scores, start=1):\n",
    "        results.append({\n",
    "            'qid': qid,\n",
    "            'docno': doc_id,\n",
    "            'rank': rank,\n",
    "            'score': score,\n",
    "            'query': query\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "retrieved_results = pd.DataFrame(results, columns=['qid', 'docno', 'rank', 'score', 'query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85084a7a",
   "metadata": {},
   "source": [
    "### <code>Mean Average Precision (MAP)</code>\n",
    "\n",
    "Mean Average Precision (MAP) is a metric used to evaluate the performance of an information retrieval system. It calculates the average precision for a set of queries and then computes the mean of these average precision values. The formula for MAP is given by:\n",
    "\n",
    "$$\\text{MAP} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{AP}(i)$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of queries.\n",
    "- $\\text{AP}(i)$ is the average precision for query $( i )$.\n",
    "\n",
    "#### Average Precision (AP)\n",
    "\n",
    "The average precision for a single query is the average of the precision values obtained at each point a relevant document is retrieved. The formula for average precision is:\n",
    "\n",
    "$$\\text{AP}(i) = \\frac{1}{R_i} \\sum_{k=1}^{|D_i|} P(k) \\cdot \\text{rel}(k)$$\n",
    "\n",
    "Where:\n",
    "- $R_i$ is the total number of relevant documents for query $( i )$.\n",
    "- $|D_i|$ is the total number of retrieved documents for query $( i )$.\n",
    "- $P(k)$ is the precision at rank $( k )$.\n",
    "- $\\text{rel}(k)$ is an indicator function equaling 1 if the document at rank $( k )$ is relevant, and 0 otherwise.\n",
    "\n",
    "#### Steps to calculate MAP:\n",
    "1. For each query, calculate the Average Precision (AP).\n",
    "2. Compute the precision at each rank where a relevant document is retrieved.\n",
    "3. Average these precision values for each query to get AP for that query.\n",
    "4. Compute the mean of the average precisions for all queries to get MAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b372f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision (MAP): 0.15203106531011265\n"
     ]
    }
   ],
   "source": [
    "# Compute Mean Average Precision (MAP)\n",
    "def calculate_map(retrieved_results, qrels):\n",
    "    avg_precision = []\n",
    "    for qid in retrieved_results['qid'].unique():\n",
    "        relevant_docs = qrels[qrels['qid'] == qid]['docno'].tolist()\n",
    "        retrieved_docs = retrieved_results[retrieved_results['qid'] == qid]['docno'].tolist()\n",
    "        \n",
    "        precision_at_k = []\n",
    "        num_relevant = 0\n",
    "        for i, doc in enumerate(retrieved_docs):\n",
    "            if doc in relevant_docs:\n",
    "                num_relevant += 1\n",
    "                precision_at_k.append(num_relevant / (i + 1))\n",
    "        \n",
    "        if len(precision_at_k) > 0:\n",
    "            avg_precision.append(np.mean(precision_at_k))\n",
    "        else:\n",
    "            avg_precision.append(0.0)\n",
    "    \n",
    "    return np.mean(avg_precision)\n",
    "\n",
    "map_score = calculate_map(retrieved_results, qrels)\n",
    "print(f\"Mean Average Precision (MAP): {map_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a509d0b",
   "metadata": {},
   "source": [
    "### <code>Precision at 10 (P@10)</code>\n",
    "\n",
    "Precision at 10, or P@10, is a metric used to evaluate the performance of an information retrieval system. It measures the proportion of relevant documents within the top 10 retrieved documents for each query. The formula for P@10 is given by:\n",
    "\n",
    "$$ \\text{P@10} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{| \\{ \\text{relevant documents in top 10 results for query } i \\} |}{10} $$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of queries.\n",
    "- ${ \\text{relevant documents in top 10 results for query } i }$ is the set of relevant documents within the top 10 retrieved documents for query \\( i \\).\n",
    "- The precision is calculated as the number of relevant documents in the top 10 divided by 10.\n",
    "\n",
    "Steps to calculate P@10:\n",
    "1. For each query, identify the top 10 retrieved documents.\n",
    "2. Count the number of these top 10 documents that are relevant according to the ground truth.\n",
    "3. Calculate the ratio of relevant documents to the total number of retrieved documents (10).\n",
    "4. Average this ratio over all queries to get the final P@10 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "200494db8dd1e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 10 (P@10): 0.6893333333333332\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_p_at_k(retrieved_results, qrels, k=10):\n",
    "    precision_scores = []\n",
    "    for qid in retrieved_results['qid'].unique():\n",
    "        relevant_docs = set(qrels[qrels['qid'] == qid]['docno'].tolist())\n",
    "        retrieved_docs = retrieved_results[retrieved_results['qid'] == qid]['docno'].tolist()[:k]\n",
    "        \n",
    "        num_relevant = len(set(retrieved_docs).intersection(relevant_docs))\n",
    "        precision_at_k = num_relevant / k if k > 0 else 0.0\n",
    "        \n",
    "        precision_scores.append(precision_at_k)\n",
    "    \n",
    "    return np.mean(precision_scores)\n",
    "\n",
    "# Example usage:\n",
    "p_at_10_score = calculate_p_at_k(retrieved_results, qrels, k=10)\n",
    "print(f\"Precision at 10 (P@10): {p_at_10_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d78ca",
   "metadata": {},
   "source": [
    "## Exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c4eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5232c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = pd.DataFrame({\n",
    "    'qid': [1, 1, 1, 2, 2, 3],\n",
    "    'docno': ['doc1', 'doc2', 'doc3', 'doc2', 'doc4', 'doc1']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10867f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_results = pd.DataFrame({\n",
    "    'qid': [1, 1, 1, 2, 2, 3],\n",
    "    'docno': ['doc1', 'doc3', 'doc5', 'doc2', 'doc6', 'doc1'],\n",
    "    'rank': [1, 2, 3, 1, 2, 1],\n",
    "    'score': [0.9, 0.8, 0.7, 0.95, 0.85, 0.75],\n",
    "    'query': ['query1', 'query1', 'query1', 'query2', 'query2', 'query3']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f2440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID: 1\n",
      "Relevant Docs: {'doc1', 'doc2', 'doc3'}\n",
      "Retrieved Docs: ['doc1', 'doc3', 'doc5']\n",
      "Number of Relevant Docs in Top 5: 2\n",
      "Precision@5: 0.4\n",
      "QID: 2\n",
      "Relevant Docs: {'doc4', 'doc2'}\n",
      "Retrieved Docs: ['doc2', 'doc6']\n",
      "Number of Relevant Docs in Top 5: 1\n",
      "Precision@5: 0.2\n",
      "QID: 3\n",
      "Relevant Docs: {'doc1'}\n",
      "Retrieved Docs: ['doc1']\n",
      "Number of Relevant Docs in Top 5: 1\n",
      "Precision@5: 0.2\n",
      "Precision at 10 (P@10): 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_p_at_k(retrieved_results, qrels, k=10):\n",
    "    precision_scores = []\n",
    "    \n",
    "    for qid in retrieved_results['qid'].unique():\n",
    "        # Extract relevant documents for the query\n",
    "        relevant_docs = set(qrels[qrels['qid'] == qid]['docno'].tolist())\n",
    "        # Extract top k retrieved documents for the query\n",
    "        retrieved_docs = retrieved_results[retrieved_results['qid'] == qid]['docno'].tolist()[:k]\n",
    "        \n",
    "        # Calculate number of relevant documents in the top k\n",
    "        num_relevant = len(set(retrieved_docs).intersection(relevant_docs))\n",
    "        # Calculate precision at k\n",
    "        precision_at_k = num_relevant / k if k > 0 else 0.0\n",
    "        \n",
    "        # Debug information\n",
    "        print(f\"QID: {qid}\")\n",
    "        print(f\"Relevant Docs: {relevant_docs}\")\n",
    "        print(f\"Retrieved Docs: {retrieved_docs}\")\n",
    "        print(f\"Number of Relevant Docs in Top {k}: {num_relevant}\")\n",
    "        print(f\"Precision@{k}: {precision_at_k}\")\n",
    "        \n",
    "        precision_scores.append(precision_at_k)\n",
    "    \n",
    "    # Return the mean precision at k across all queries\n",
    "    return np.mean(precision_scores)\n",
    "\n",
    "# Sample qrels DataFrame (replace with actual qrels data)\n",
    "qrels = pd.DataFrame({\n",
    "    'qid': [1, 1, 1, 2, 2, 3],\n",
    "    'docno': ['doc1', 'doc2', 'doc3', 'doc2', 'doc4', 'doc1']\n",
    "})\n",
    "\n",
    "# Sample retrieved results DataFrame (replace with actual retrieved results data)\n",
    "retrieved_results = pd.DataFrame({\n",
    "    'qid': [1, 1, 1, 2, 2, 3],\n",
    "    'docno': ['doc1', 'doc3', 'doc5', 'doc2', 'doc6', 'doc1'],\n",
    "    'rank': [1, 2, 3, 1, 2, 1],\n",
    "    'score': [0.9, 0.8, 0.7, 0.95, 0.85, 0.75],\n",
    "    'query': ['query1', 'query1', 'query1', 'query2', 'query2', 'query3']\n",
    "})\n",
    "\n",
    "# Example usage\n",
    "p_at_10_score = calculate_p_at_k(retrieved_results, qrels, k=5)\n",
    "print(f\"Precision at 10 (P@10): {p_at_10_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fce2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
